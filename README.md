# PlacasCNN - Sistema ALPR (Automatic License Plate Recognition)

Sistema completo de reconocimiento automÃ¡tico de placas vehiculares usando YOLOv8 para detecciÃ³n, segmentaciÃ³n clÃ¡sica de caracteres, y CNN para clasificaciÃ³n.

## ğŸ“‹ CaracterÃ­sticas

- **DetecciÃ³n de placas**: YOLOv8 para detectar placas en imÃ¡genes
- **SegmentaciÃ³n de caracteres**: Algoritmo clÃ¡sico robusto (con opciÃ³n a CNN)
- **ClasificaciÃ³n de caracteres**: CNN entrenada para reconocer 36 clases (0-9, A-Z)
- **Fallback OCR**: EasyOCR como respaldo cuando la CNN falla
- **Arquitectura modular**: FÃ¡cil de extender y mantener

## ğŸ“ Estructura del Proyecto

```
PlacasCNN/
â”œâ”€â”€ config.py                    # ConfiguraciÃ³n centralizada
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â”œâ”€â”€ setup_dataset.py            # Utilidades para dataset
â”œâ”€â”€ train_yolo.py               # Entrenamiento del detector
â”œâ”€â”€ train_classifier.py         # Entrenamiento del clasificador
â”œâ”€â”€ predict.py                  # Script de predicciÃ³n
â”œâ”€â”€ detectors/
â”‚   â””â”€â”€ plate_detector.py       # Detector de placas (YOLOv8)
â”œâ”€â”€ segmenters/
â”‚   â”œâ”€â”€ classical_segmenter.py  # Segmentador clÃ¡sico
â”‚   â””â”€â”€ cnn_segmenter.py        # Segmentador CNN (placeholder)
â”œâ”€â”€ recognizers/
â”‚   â”œâ”€â”€ cnn_classifier.py       # Clasificador CNN de caracteres
â”‚   â””â”€â”€ easyocr_fallback.py     # Fallback con EasyOCR
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ alpr_pipeline.py        # Pipeline completo de ALPR
â””â”€â”€ utils/
    â”œâ”€â”€ image_utils.py          # Utilidades de imagen
    â””â”€â”€ plate_format.py         # ValidaciÃ³n de formato
```

## ğŸš€ InstalaciÃ³n

### Requisitos Previos
- Python 3.8 o superior
- pip
- (Opcional) GPU con CUDA para entrenamiento mÃ¡s rÃ¡pido

### Pasos de InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <url-del-repo>
cd PlacasCNN
```

2. **Crear entorno virtual (recomendado)**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

## ğŸ“Š PreparaciÃ³n del Dataset

### 1. Dataset de DetecciÃ³n (YOLOv8)

Necesitas un dataset en formato Roboflow con:
- Carpetas: `train/`, `valid/`, `test/`
- Cada carpeta con subcarpetas `images/` y `labels/`
- Archivo `data.yaml` con configuraciÃ³n

**Descomprimir dataset:**

```python
from setup_dataset import unzip_dataset, verify_dataset_structure
from config import create_directories

create_directories()
unzip_dataset("path/to/your/dataset.zip")
verify_dataset_structure()
```

### 2. Dataset de Caracteres (Clasificador)

Estructura necesaria:
```
data/char_dataset/
â”œâ”€â”€ 0/
â”‚   â”œâ”€â”€ img1.png
â”‚   â”œâ”€â”€ img2.png
â”‚   â””â”€â”€ ...
â”œâ”€â”€ 1/
â”œâ”€â”€ 2/
â”œâ”€â”€ ...
â”œâ”€â”€ A/
â”œâ”€â”€ B/
â””â”€â”€ Z/
```

Cada carpeta contiene imÃ¡genes del caracter correspondiente.

## ğŸ¯ Entrenamiento

### 1. Entrenar Detector YOLOv8

```bash
python train_yolo.py --data data/dataset/data.yaml
```

**ParÃ¡metros personalizables en `config.py`:**
- `epochs`: NÃºmero de Ã©pocas (default: 50)
- `imgsz`: TamaÃ±o de imagen (default: 640)
- `batch`: TamaÃ±o de batch (default: 8)
- `device`: GPU/CPU (default: auto-detect)

### 2. Entrenar Clasificador de Caracteres

```bash
python train_classifier.py --data data/char_dataset --epochs 50
```

El modelo se guardarÃ¡ en `models/classifier/classifier.h5`

**Arquitectura del clasificador:**
- Input: 32x32 grayscale
- 3 bloques Conv2D + MaxPool
- GlobalAveragePooling
- Dense(128) + Dense(36)
- ActivaciÃ³n: softmax

## ğŸ”® PredicciÃ³n

### Uso BÃ¡sico

```bash
python predict.py --image path/to/image.jpg
```

### Opciones Avanzadas

```bash
# Sin fallback de EasyOCR
python predict.py --image path/to/image.jpg --no-easyocr

# Con modelo clasificador personalizado
python predict.py --image path/to/image.jpg --classifier path/to/model.h5
```

### Uso ProgramÃ¡tico

```python
from pipeline.alpr_pipeline import ALPRPipeline
from config import CLASSIFIER_MODEL_DIR
from pathlib import Path

# Inicializar pipeline
classifier_path = Path(CLASSIFIER_MODEL_DIR) / "classifier.h5"
pipeline = ALPRPipeline(
    classifier_model=str(classifier_path),
    use_easyocr=True,
    segmenter_type="classical"
)

# Procesar imagen
results = pipeline.recognize_from_path(
    "path/to/image.jpg",
    save_crops=True,
    visualize=True
)

# Resultados
for result in results:
    print(f"Placa: {result['plate']}")
    print(f"MÃ©todo: {result['method']}")
    print(f"Confianza: {result['conf']:.2f}")
```

## âš™ï¸ ConfiguraciÃ³n

Edita `config.py` para personalizar:

### Rutas
- `DATA_DIR`: Directorio de datos
- `MODELS_DIR`: Directorio de modelos
- `RESULTS_DIR`: Directorio de resultados

### ParÃ¡metros de YOLO
```python
YOLO_TRAIN_CONFIG = {
    "epochs": 50,
    "imgsz": 640,
    "batch": 8,
    "device": None,
}
```

### ParÃ¡metros del Clasificador
```python
CLASSIFIER_CONFIG = {
    "img_size": 32,
    "batch": 64,
    "epochs": 50,
    "num_classes": 36,
}
```

### ParÃ¡metros del Pipeline
```python
ALPR_CONFIG = {
    "yolo_conf": 0.4,        # Umbral de confianza
    "yolo_iou": 0.45,        # Umbral IoU
    "save_crops": True,      # Guardar recortes
    "use_easyocr_fallback": True,  # Usar fallback
}
```

## ğŸ”§ MÃ³dulos Principales

### PlateDetector
Detecta placas en imÃ¡genes usando YOLOv8.

```python
from detectors.plate_detector import PlateDetector

detector = PlateDetector()
crops = detector.detect(image, conf=0.4, iou=0.45)
```

### ClassicalSegmenter
Segmenta caracteres usando procesamiento de imagen clÃ¡sico.

```python
from segmenters.classical_segmenter import ClassicalSegmenter

segmenter = ClassicalSegmenter()
chars = segmenter.segment(plate_image)
```

### CharacterClassifier
Clasifica caracteres individuales.

```python
from recognizers.cnn_classifier import CharacterClassifier

classifier = CharacterClassifier("path/to/model.h5")
char, confidence = classifier.classify(char_image)
```

### ALPRPipeline
Pipeline completo que orquesta todos los componentes.

```python
from pipeline.alpr_pipeline import ALPRPipeline

pipeline = ALPRPipeline(
    yolo_model=None,           # Usa modelo entrenado
    classifier_model="path/to/classifier.h5",
    use_easyocr=True,
    segmenter_type="classical"
)

results = pipeline.recognize_from_path("image.jpg")
```

## ğŸ“ˆ Flujo de Trabajo Completo

1. **Preparar Dataset**
   - Obtener dataset de placas (Roboflow)
   - Descomprimir con `setup_dataset.py`
   - Preparar dataset de caracteres

2. **Entrenar Modelos**
   - Entrenar YOLOv8: `python train_yolo.py`
   - Entrenar clasificador: `python train_classifier.py`

3. **Evaluar**
   - Probar con imÃ¡genes individuales
   - Ajustar parÃ¡metros en `config.py`

4. **ProducciÃ³n**
   - Usar `ALPRPipeline` en tu aplicaciÃ³n
   - Considerar optimizaciones (TFLite, ONNX)

## ğŸ¨ PersonalizaciÃ³n

### Cambiar Formato de Placa

Edita `utils/plate_format.py`:

```python
# Ejemplo para formato mexicano ABC-123-D
PLATE_REGEX = re.compile(r'^[A-Z]{3}[-\s]?\d{3}[-\s]?[A-Z]$')

def is_valid_plate(s):
    # Tu lÃ³gica de validaciÃ³n
    pass
```

### Agregar MÃ¡s Clases al Clasificador

Modifica `config.py`:

```python
CLASSIFIER_CONFIG = {
    "num_classes": 38,  # Agregar mÃ¡s caracteres
    "class_map": list("0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ-Â·")
}
```

### Usar Segmentador CNN

1. Entrenar modelo de segmentaciÃ³n
2. Implementar mÃ©todo `segment()` en `cnn_segmenter.py`
3. Usar en pipeline:

```python
pipeline = ALPRPipeline(
    segmenter_type="cnn",
    segmenter_model="path/to/segmenter.h5"
)
```

## ğŸ› SoluciÃ³n de Problemas

### Error: "No se encontrÃ³ data.yaml"
- Verifica que el dataset estÃ© descomprimido correctamente
- AsegÃºrate de que `data.yaml` estÃ© en la raÃ­z del dataset

### Error: "No module named 'ultralytics'"
```bash
pip install ultralytics
```

### Baja precisiÃ³n en detecciÃ³n
- Aumentar epochs de entrenamiento
- Obtener mÃ¡s datos de entrenamiento
- Ajustar `yolo_conf` en `config.py`

### SegmentaciÃ³n no encuentra caracteres
- La imagen puede estar mal orientada
- Ajustar parÃ¡metros en `ClassicalSegmenter`
- Considerar preprocesamiento adicional

### Clasificador confunde caracteres similares
- Aumentar datos de entrenamiento
- Aumentar epochs
- Considerar data augmentation mÃ¡s agresivo

## ğŸ“ TODOs / Mejoras Futuras

- [ ] Implementar segmentador CNN (UNet)
- [ ] Script para extraer caracteres automÃ¡ticamente
- [ ] Sistema de evaluaciÃ³n (mAP, accuracy)
- [ ] API REST con FastAPI
- [ ] Soporte para video en tiempo real
- [ ] OptimizaciÃ³n con TensorRT/ONNX
- [ ] Docker container
- [ ] Tests unitarios

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea tu rama de feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

## ğŸ‘¥ Autores

- Tu nombre - [GitHub Profile]

## ğŸ™ Agradecimientos

- Ultralytics por YOLOv8
- Roboflow por facilitar datasets
- JaidedAI por EasyOCR
- TensorFlow/Keras team